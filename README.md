Ethics in AI: Case Studies and Bias Analysis
This project explores ethical challenges in artificial intelligence through theoretical analysis, real-world case studies, and a practical dataset audit using the COMPAS recidivism dataset. It is divided among five team members, each responsible for a distinct part of the final report.

Contributions by Members

- **Member 1:** Theoretical understanding of algorithmic bias, transparency vs explainability, and GDPR’s role in AI ethics.
- **Member 2:** Case study of bias in Amazon’s hiring AI, proposing remediation strategies and fairness metrics.
- **Member 3:** Facial recognition misuse in policing and ethical recommendations for responsible deployment.
- **Member 4:** Technical audit of COMPAS dataset using Python and IBM’s AI Fairness 360 toolkit.
- **Member 5:** Personal ethical reflection on responsible AI development.

Tools & Libraries Used
 
- Jupyter Notebook  
- VS Code  
- Microsoft Word (report compilation)

 Key Ethical Principles Addressed

- **Justice** – Ensuring fairness across demographic groups  
- **Non-maleficence** – Avoiding harm through rigorous model testing  
- **Autonomy** – Respecting users’ control over data  
- **Sustainability** – Promoting long-term social and environmental wellbeing  

 How to Run the Notebook

1. Open `AuditedForBias.ipynb` in Jupyter Notebook.
2. Install dependencies if not already:
   ```bash
   pip install aif360 pandas matplotlib scikit-learn
